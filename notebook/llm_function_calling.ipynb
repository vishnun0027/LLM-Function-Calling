{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# initialize llm\n",
    "def initialize_llm(model_name=\"llama3.2:3b\", temperature=0, max_tokens=50):\n",
    "    \"\"\"\n",
    "    Initializes the ChatOllama model with specified parameters.\n",
    "    Returns:\n",
    "        ChatOllama: Instance of ChatOllama model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        llm = ChatOllama(\n",
    "            model=model_name,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens,\n",
    "        )\n",
    "        print(\"Model initialized successfully.\")\n",
    "        return llm\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing the model: {e}\")\n",
    "        return None\n",
    "# Initialize the model\n",
    "model = initialize_llm()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ask something related to external system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not sure what time it is, as I'm a text-based AI and don't have real-time access to your location. However, I can suggest some ways for you to find out the current time:\n",
      "\n",
      "1. Check your phone or computer's clock.\n",
      "2. Look at a physical clock or watch.\n",
      "3. Search for \"current time\" on a search engine like Google.\n",
      "\n",
      "If you need help with anything else, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "response = model.invoke([HumanMessage(content=\"hey what's the time\")]) \n",
    "print(parser.invoke(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### implement llm function calling/too calling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "\n",
    "# create fucnction/tool \n",
    "\n",
    "# get current time\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"\n",
    "    Returns the current time as a formatted string like 'HH:MM:SS AM/PM', in 12-hour format with AM/PM notation.\n",
    "    \n",
    "    Returns:\n",
    "        str: A string representing the current time in the format 'HH:MM:SS AM/PM'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the current date and time\n",
    "        now = datetime.now()\n",
    "\n",
    "        # Format as a string in 12-hour format with AM/PM notation\n",
    "        time_str = now.strftime(\"%I:%M:%S %p\")\n",
    "\n",
    "        # Return the formatted string\n",
    "        return time_str\n",
    "    except Exception as e:\n",
    "        # Return an error message if an exception occurs\n",
    "        return f\"An error occurred while fetching the time: {e}\"\n",
    "@tool \n",
    "def get_weather(location: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetches the current weather data for a specified city\n",
    "\n",
    "    Args:\n",
    "        location (str): Location for weather query (e.g., city name).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dummy weather forecast response.\n",
    "    \"\"\"\n",
    "    # Dummy response\n",
    "    return {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"25Â°C\",\n",
    "        \"condition\": \"Sunny\",\n",
    "        \"humidity\": \"60%\",\n",
    "        \"wind_speed\": \"15 km/h\"\n",
    "    }    \n",
    "\n",
    "# get current date\n",
    "@tool\n",
    "def current_date() -> str:\n",
    "    \"\"\"\n",
    "    Return the current date in YYYY-MM-DD format.\n",
    "    \n",
    "    Returns:\n",
    "        str: A string representing the current date in the format 'YYYY-MM-DD'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return date.today().strftime(\"%Y-%m-%d\")\n",
    "    except Exception as e:\n",
    "        return f\"Error occurred while fetching the date: {e}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "         get_current_time,\n",
    "         current_date,\n",
    "         get_weather\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind the tools to the LLM\n",
    "llm_with_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm_with_tools.invoke([HumanMessage(content=\"hey what's the time\")]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_current_time (fb112caa-a2b9-45bc-a6b3-06e4cfe3495d)\n",
      " Call ID: fb112caa-a2b9-45bc-a6b3-06e4cfe3495d\n",
      "  Args:\n"
     ]
    }
   ],
   "source": [
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  get_weather (13cebafd-5e37-472e-9dfa-87fec637a4ae)\n",
      " Call ID: 13cebafd-5e37-472e-9dfa-87fec637a4ae\n",
      "  Args:\n",
      "    location: delhi\n"
     ]
    }
   ],
   "source": [
    "response = llm_with_tools.invoke([HumanMessage(content=\"hey what's weather in delhi\")]) \n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIPro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
